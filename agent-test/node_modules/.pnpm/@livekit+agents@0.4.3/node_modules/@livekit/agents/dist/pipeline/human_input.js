import { AudioStream, RoomEvent, TrackSource } from '@livekit/rtc-node';
import { EventEmitter } from 'node:events';
import { log } from '../log.js';
import { SpeechEventType } from '../stt/stt.js';
import { CancellablePromise, gracefullyCancel } from '../utils.js';
import { VADEventType } from '../vad.js';
export var HumanInputEvent;
(function (HumanInputEvent) {
    HumanInputEvent[HumanInputEvent["START_OF_SPEECH"] = 0] = "START_OF_SPEECH";
    HumanInputEvent[HumanInputEvent["VAD_INFERENCE_DONE"] = 1] = "VAD_INFERENCE_DONE";
    HumanInputEvent[HumanInputEvent["END_OF_SPEECH"] = 2] = "END_OF_SPEECH";
    HumanInputEvent[HumanInputEvent["FINAL_TRANSCRIPT"] = 3] = "FINAL_TRANSCRIPT";
    HumanInputEvent[HumanInputEvent["INTERIM_TRANSCRIPT"] = 4] = "INTERIM_TRANSCRIPT";
})(HumanInputEvent || (HumanInputEvent = {}));
export class HumanInput extends EventEmitter {
    #closed = false;
    #room;
    #vad;
    #stt;
    #participant;
    #subscribedTrack;
    #recognizeTask;
    #speaking = false;
    #speechProbability = 0;
    #logger = log();
    constructor(room, vad, stt, participant) {
        super();
        this.#room = room;
        this.#vad = vad;
        this.#stt = stt;
        this.#participant = participant;
        this.#room.on(RoomEvent.TrackPublished, this.#subscribeToMicrophone.bind(this));
        this.#room.on(RoomEvent.TrackSubscribed, this.#subscribeToMicrophone.bind(this));
        this.#subscribeToMicrophone();
    }
    #subscribeToMicrophone() {
        if (!this.#participant) {
            this.#logger.error('Participant is not set');
            return;
        }
        let microphonePublication = undefined;
        for (const publication of this.#participant.trackPublications.values()) {
            if (publication.source === TrackSource.SOURCE_MICROPHONE) {
                microphonePublication = publication;
                break;
            }
        }
        if (!microphonePublication) {
            return;
        }
        if (!microphonePublication.subscribed) {
            microphonePublication.setSubscribed(true);
        }
        const track = microphonePublication.track;
        if (track && track !== this.#subscribedTrack) {
            this.#subscribedTrack = track;
            if (this.#recognizeTask) {
                this.#recognizeTask.cancel();
            }
            const audioStream = new AudioStream(track, 16000);
            // eslint-disable-next-line @typescript-eslint/no-unused-vars
            this.#recognizeTask = new CancellablePromise(async (resolve, _, onCancel) => {
                let cancelled = false;
                onCancel(() => {
                    cancelled = true;
                });
                const sttStream = this.#stt.stream();
                const vadStream = this.#vad.stream();
                const audioStreamCo = async () => {
                    for await (const ev of audioStream) {
                        if (cancelled)
                            return;
                        sttStream.pushFrame(ev);
                        vadStream.pushFrame(ev);
                    }
                };
                const vadStreamCo = async () => {
                    for await (const ev of vadStream) {
                        if (cancelled)
                            return;
                        switch (ev.type) {
                            case VADEventType.START_OF_SPEECH:
                                this.#speaking = true;
                                this.emit(HumanInputEvent.START_OF_SPEECH, ev);
                                break;
                            case VADEventType.INFERENCE_DONE:
                                this.#speechProbability = ev.probability;
                                this.emit(HumanInputEvent.VAD_INFERENCE_DONE, ev);
                                break;
                            case VADEventType.END_OF_SPEECH:
                                this.#speaking = false;
                                this.emit(HumanInputEvent.END_OF_SPEECH, ev);
                                break;
                        }
                    }
                };
                const sttStreamCo = async () => {
                    for await (const ev of sttStream) {
                        if (cancelled)
                            return;
                        if (ev.type === SpeechEventType.FINAL_TRANSCRIPT) {
                            this.emit(HumanInputEvent.FINAL_TRANSCRIPT, ev);
                        }
                        else if (ev.type == SpeechEventType.INTERIM_TRANSCRIPT) {
                            this.emit(HumanInputEvent.INTERIM_TRANSCRIPT, ev);
                        }
                    }
                };
                await Promise.all([audioStreamCo(), vadStreamCo(), sttStreamCo()]);
                sttStream.close();
                vadStream.close();
                resolve();
            });
        }
    }
    get speaking() {
        return this.#speaking;
    }
    get speakingProbability() {
        return this.#speechProbability;
    }
    async close() {
        if (this.#closed) {
            throw new Error('HumanInput already closed');
        }
        this.#closed = true;
        this.#room.removeAllListeners();
        this.#speaking = false;
        if (this.#recognizeTask) {
            await gracefullyCancel(this.#recognizeTask);
        }
    }
}
//# sourceMappingURL=human_input.js.map